{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b560092",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89885fa7",
   "metadata": {},
   "source": [
    "```bash\n",
    "conda create -n edu4 python=3.11 jupyter matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23589d",
   "metadata": {},
   "source": [
    "```bash \n",
    "! pip install -U -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16321f",
   "metadata": {},
   "source": [
    "```bash\n",
    "! pip install -U numpy\n",
    "! pip install -U scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cab43a",
   "metadata": {},
   "source": [
    "## Update repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad216da",
   "metadata": {},
   "source": [
    "## Add import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baafb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2930983",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del module_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1e9c8",
   "metadata": {},
   "source": [
    "## Organize imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae177357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730a69b-c412-4bfe-a3a8-7ff234315280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25750a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125950ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning import Trainer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f31e93",
   "metadata": {},
   "source": [
    "#### Number of CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = multiprocessing.cpu_count()\n",
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f41838-322d-41e8-b8e1-6712089703c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf4792-19f1-4d01-b9c2-ddea2462cadc",
   "metadata": {},
   "source": [
    "## Initialize Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd545b8-0e15-41e9-92a9-4d0bf260c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "checkpoint_dir = PATH / 'checkpoints' / 'sae_l1_128_mnist'\n",
    "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "checkpoint_path1 = checkpoint_dir / 'best-checkpoint-v1.ckpt'\n",
    "checkpoint_path2 = checkpoint_dir / 'best-checkpoint.ckpt'\n",
    "\n",
    "image_dir = PATH / 'images'\n",
    "image_path = image_dir / 'l1_128.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07aad4-53a7-456b-b026-80295db7d84d",
   "metadata": {},
   "source": [
    "## Initialize simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddebc9-6b60-403d-aaa1-13c71e3215e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated MNIST data loaders with normalization and validation set\n",
    "def prepare_data(batch_size=128):\n",
    "    # Normalize to [0, 1] for MNIST\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Mean and std from MNIST\n",
    "        transforms.Lambda(lambda x: x.view(-1))  # Flatten the image\n",
    "    ])\n",
    "\n",
    "    # Training set\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Validation set\n",
    "    val_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dataset, train_loader, val_dataset, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2e843-2637-46e4-bd85-c66eeb5224a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_loader, val_dataset, val_loader = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807137b2-c1f9-42eb-a4aa-2ad0f60c93b2",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecbb2e-8222-42dd-a40e-84ae4900b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, input_size=784, hidden_size=512, sparsity_target=0.05, sparsity_weight=1e-3):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        # Hyperparameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sparsity_target = sparsity_target\n",
    "        self.sparsity_weight = sparsity_weight\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        # Check for NaN or Inf values in the input\n",
    "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "            print(\"Data contains NaN or Inf values!\")\n",
    "\n",
    "        x_hat, encoded = self.forward(x)\n",
    "\n",
    "        # Reconstruction loss\n",
    "        recon_loss = self.criterion(x_hat, x)\n",
    "\n",
    "        # Sparsity regularization (KL Divergence)\n",
    "        rho_hat = torch.mean(encoded, dim=0)\n",
    "        rho = torch.ones_like(rho_hat) * 0.05\n",
    "        kl_loss = torch.sum(self.kl_divergence(rho, rho_hat))\n",
    "        loss = recon_loss + 1e-3 * kl_loss\n",
    "\n",
    "        # Check for NaN or Inf values in the loss\n",
    "        if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "            print(\"Loss contains NaN or Inf values!\")\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x_hat, encoded = self.forward(x)\n",
    "\n",
    "        # Reconstruction loss\n",
    "        recon_loss = self.criterion(x_hat, x)\n",
    "        \n",
    "        # Sparsity regularization (KL Divergence)\n",
    "        rho_hat = torch.mean(encoded, dim=0)\n",
    "        rho = torch.ones_like(rho_hat) * self.sparsity_target\n",
    "        kl_loss = torch.sum(self.kl_divergence(rho, rho_hat))\n",
    "        loss = recon_loss + self.sparsity_weight * kl_loss\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Adding weight decay for L2 regularization\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        \n",
    "        # Adding learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def kl_divergence(p, p_hat):\n",
    "        # Adding small epsilon (1e-10) to prevent division by zero or log(0)\n",
    "        eps = 1e-10\n",
    "        p_hat = torch.clamp(p_hat, eps, 1 - eps)  # Clamp to ensure p_hat is between [eps, 1-eps]\n",
    "        return p * torch.log(p / p_hat + eps) + (1 - p) * torch.log((1 - p) / (1 - p_hat + eps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170865ef-a222-407e-9467-c9d82e08e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=128):\n",
    "        super().__init__()\n",
    "        # Hyperparameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def encode(self, x):\n",
    "        x_in = x if len(x.shape) == 1 else x.view(-1)\n",
    "        z = self.encoder(x_in)\n",
    "\n",
    "        return z\n",
    "\n",
    "    def encode_np(self, x):\n",
    "        z = self.encode(x)\n",
    "        z_np = z.cpu().detach().numpy()\n",
    "\n",
    "        return z_np\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aaaece-772e-49fc-8a7b-579a88afd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_ds(ds):\n",
    "    with tqdm(ds) as prds:\n",
    "        zs = np.array(\n",
    "            [model.encode_np(x) for x, _ in prds]\n",
    "        )\n",
    "\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33773196-d9c1-45ca-9bd0-f3a6a33abb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zs(ds):\n",
    "    z_kl = dict()\n",
    "    z_ks = dict()\n",
    "    with tqdm(ds) as prds:\n",
    "        for x, y in prds:\n",
    "            z_k = model.encode_np(x)\n",
    "            z_kl.setdefault(y, list())\n",
    "            z_kl[y].append(z_k)\n",
    "    for k, v in z_kl.items():\n",
    "        z_ks[k] = np.array(v)\n",
    "\n",
    "    return z_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac5e404-66f7-4b2e-825c-06d528e0e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_idx(z, zs):\n",
    "    with tqdm(zs) as przs:\n",
    "        gr = np.array(\n",
    "            [i for i, z_s in enumerate(przs) if (z <= z_s).all()]\n",
    "        )\n",
    "\n",
    "    return gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889db223-4285-46bc-81ec-10ad3ce878f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAE(hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be26253-65d3-4dc0-ae57-88a9bdee023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path2, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9534593-e608-4bbd-8919-1909a6aa8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint['state_dict']\n",
    "state_dict_fn = dict()\n",
    "for k, v in state_dict.items():\n",
    "    k = k.replace('encoder.', 'encoder.0.')\n",
    "    k = k.replace('decoder.', 'decoder.0.')\n",
    "    state_dict_fn[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0e227-7c33-4ac4-bad3-29eccd074146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798dd24-0392-47dd-81e6-a0ecbec6d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e6cdb-7908-40d3-9c5d-01cfddfb7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the learned features (filters) by plotting the encoder weights\n",
    "def visualize_weights(autoencoder):\n",
    "    weights = autoencoder.encoder[0].weight.data.cpu().numpy()\n",
    "    fig, axes = plt.subplots(8, 16, figsize=(32, 32))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.set_title(f'{i + 1}')\n",
    "        ax.imshow(weights[i].reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.savefig(image_path)\n",
    "    plt.show()\n",
    "\n",
    "# Call visualization functions\n",
    "visualize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0e8bb-3ae0-45e9-ad46-cce0a8ef98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the learned features (filters) by plotting the encoder weights\n",
    "def visualize_activations(autoencoder, z):\n",
    "    indices = torch.nonzero(z)\n",
    "    weights = autoencoder.encoder[0].weight.data.cpu().numpy()\n",
    "    fig, axes = plt.subplots(len(indices), 1, figsize=(128, 128))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.set_title(f'{indices[i].cpu().detach().numpy()} {z[indices[i]].cpu().detach().numpy()}')\n",
    "        ax.imshow(weights[indices[i]].reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f0f49-cd0c-48b0-b3bd-533e9cb517d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array([y for _, y in train_dataset])\n",
    "val_y = np.array([y for _, y in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1f229-c343-417d-83da-9bd4a0fb9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = find_zs(train_dataset)\n",
    "z_val = find_zs(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9623cc-1511-4d90-9d56-73548f7fe851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_z = inference_ds(train_dataset)\n",
    "val_z = inference_ds(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb93043-0271-4cb6-83c3-9d2df7477345",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = val_dataset[12]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1315f-66bc-418d-864b-6f097bbb050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_dataset[32]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0addecb-dd60-462b-84f6-daf95a25be46",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08e054-f7fe-4590-97f3-55dc9c97b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode_np(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44fac3c-a6f4-4901-b138-f182df9a8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a88ad-2c24-4042-9acf-fc9e50ecc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_z[0].argsort()[-2:], val_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4b890-6208-457d-86b9-0b6ac065c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_z[0][val_z[0].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f44a93c-c59b-456a-a4a5-6614d6f4e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c2040-ac25-44fc-b9a5-6631ab432666",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe7870-a0e3-4805-99d9-bb53909d36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a1d86-6512-4ced-9a61-5f17296b547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_z), len(train_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ece02e-55a0-4c80-8c57-8bebb0ddb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_z.shape, train_z.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363aaea-c150-4b9d-a157-cba35589842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_x = z_val[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc536b-87e3-4d74-a61d-8120eaedf6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 55\n",
    "k = 79\n",
    "q = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbf0c8-a102-4e0a-b1ef-5bbe57a6a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_t = np.zeros(val_z[0].shape)\n",
    "z_t[t] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd14c64-7dd0-44f3-8730-27f6109c2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ge = gr_idx(z_t, val_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5da3d-1f48-44f3-989b-694e0230ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_k = np.zeros(val_z[0].shape)\n",
    "z_k[k] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7fe44-0fc5-4aa2-bc84-ecac9f8a8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_q = np.zeros(val_z[0].shape)\n",
    "z_q[q] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adecea8-c960-4e14-aa09-498ac99cf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ge = gr_idx(z_t, val_z)\n",
    "k_ge = gr_idx(z_k, val_z)\n",
    "q_ge = gr_idx(z_q, val_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281192f4-f81c-40f3-bffd-a88f9d5b364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y[t_ge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cb8a7-f5b7-4af8-a0b2-f39f809eb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y[k_ge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a696a-813d-4172-a159-a159e9bef0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y[q_ge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33983836-6c15-4836-91d3-16a693ffb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_qk = np.maximum(z_q, z_k)\n",
    "z_qk[k], z_qk[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f8e5a-f873-4248-a160-b5cc21a37698",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tq = np.maximum(z_q, z_t)\n",
    "z_tq[t], z_tq[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c26741-a9d0-4a84-b2c9-d38355f9066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tq_gr = gr_idx(z_tq, val_z)\n",
    "tq_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196ceee-f89f-4bc4-ace0-209af5494ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_qk = np.maximum(z_q, z_k)\n",
    "z_qk[k], z_qk[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634eaeb-33ed-44aa-9ddf-a7abec6faeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y[tq_gr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbc3b4-1c08-459d-94b9-16e68bc866b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y[qk_gr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394863f-ea29-4ea0-8b00-afa84971f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da37ca9-aefd-4b58-9a8f-24a8300a73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75082a2-ae8f-4724-ac74-c337f58540af",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_min = np.min(z_ge, axis=0)\n",
    "z_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387c7c5-ab4c-4ffa-9896-eafc5e6ffeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_min[np.argsort(z_min)[-6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b59a7e-9dc0-4c03-b36e-0c17b2442484",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ge = np.array([i for i, z_r in enumerate(val_z) if (z_min <= z_r).all()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f5520-eaab-4b55-baa0-2728facbb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in id_ge:\n",
    "    print(val_dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ca682-c1b1-4eec-94d1-70b33c10f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b898b59-f7ae-43ac-85a4-6d81217fbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ge[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc0c6f-93c7-4d8d-a9eb-4a26edad8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25408d2b-4502-42de-8ab6-d184be79aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape, torch.nonzero(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d90f1d-2a49-4496-9b0c-2f75fb47426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call visualization functions\n",
    "visualize_activations(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04ffc9-65fa-480f-9892-ecb7cc1f13b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
