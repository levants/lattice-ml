{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b560092",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89885fa7",
   "metadata": {},
   "source": [
    "```bash\n",
    "conda create -n edu4 python=3.11 jupyter matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23589d",
   "metadata": {},
   "source": [
    "```bash \n",
    "! pip install -U -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16321f",
   "metadata": {},
   "source": [
    "```bash\n",
    "! pip install -U numpy\n",
    "! pip install -U scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cab43a",
   "metadata": {},
   "source": [
    "## Update repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad216da",
   "metadata": {},
   "source": [
    "## Add import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baafb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2930983",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccfcbd-f80f-4f27-b3a0-3f06deade10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del module_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1e9c8",
   "metadata": {},
   "source": [
    "## Organize imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927f283-cc9b-4268-be85-2874379b118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    BitsAndBytesConfig, \n",
    "    AutoTokenizer, \n",
    "    GPT2Tokenizer, \n",
    "    GPT2Model\n",
    ")\n",
    "from huggingface_hub import hf_hub_download, notebook_login\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e0e45-414d-4190-844f-7b44801b2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319114e-c41f-4894-a05d-c4b428289a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae177357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730a69b-c412-4bfe-a3a8-7ff234315280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25750a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f802d-fa9c-4e26-9df1-ae621014e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee894933-eba4-4742-8fa2-51b2cff5cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lattmc.fca.utils import *\n",
    "from src.lattmc.fca.data_utils import *\n",
    "from src.lattmc.fca.image_utils import *\n",
    "from src.lattmc.fca.models import *\n",
    "from src.lattmc.fca.fca_utils import *\n",
    "from src.lattmc.fca.image_gens import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f31e93",
   "metadata": {},
   "source": [
    "#### Number of CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = multiprocessing.cpu_count()\n",
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f41838-322d-41e8-b8e1-6712089703c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c0d14-575c-491c-88a3-85f70fae7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the most part I'll try to import functions and classes near where they are used\n",
    "# to make it clear where they come from.\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf4792-19f1-4d01-b9c2-ddea2462cadc",
   "metadata": {},
   "source": [
    "## Initialize Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd545b8-0e15-41e9-92a9-4d0bf260c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "checkpoint_dir = PATH / 'saes'\n",
    "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "checkpoint_path1 = checkpoint_dir / 'best-checkpoint-v1.ckpt'\n",
    "checkpoint_path2 = checkpoint_dir / 'best-checkpoint.ckpt'\n",
    "\n",
    "image_dir = PATH / 'images'\n",
    "image_path = image_dir / '1024.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07aad4-53a7-456b-b026-80295db7d84d",
   "metadata": {},
   "source": [
    "## Initialize simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddebc9-6b60-403d-aaa1-13c71e3215e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts\n",
    "texts = [\n",
    "    \"The encoded string is U29mdHdhcmUgRW5naW5lZXJpbmc=\",  # Base64 encoded text\n",
    "    \"Recent advancements in deep learning have revolutionized artificial intelligence.\",  # Academic language\n",
    "    \"Implementing machine learning algorithms to decode base64 strings enhances data processing efficiency.\"  # Combination of topics\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807137b2-c1f9-42eb-a4aa-2ad0f60c93b2",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecbb2e-8222-42dd-a40e-84ae4900b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'gpt2-small'\n",
    "model_name = 'gpt2'\n",
    "# Load GPT-2 model and tokenizer\n",
    "gpt2_model = GPT2Model.from_pretrained(model_name).to(device)\n",
    "# gpt2_model = HookedTransformer.from_pretrained('gpt2-small', device=device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# Assign the EOS token as the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load the pre-trained sparse autoencoder for GPT-2 small, layer 8\n",
    "sae, _, _ = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",  # Pre-trained SAE release\n",
    "    sae_id=\"blocks.8.hook_resid_pre\",  # Target layer in GPT-2\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead24a57-e6a8-43e2-978b-ec2934d38b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "# Get hidden states from GPT-2\n",
    "with torch.no_grad():\n",
    "    outputs = gpt2_model(**inputs, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states[8]\n",
    "\n",
    "# Pass hidden states through the sparse autoencoder\n",
    "with torch.no_grad():\n",
    "    encoded_features = sae.encode(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad32562-bc23-41ef-9307-41a1441b248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c628c1-f3c3-4e29-8748-4a79335ae1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "# sae.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n",
    "# with torch.no_grad():\n",
    "#     # activation store can give us tokens.\n",
    "#     _, cache = gpt2_model.run_with_cache(inputs, prepend_bos=True)\n",
    "\n",
    "#     # Use the SAE\n",
    "#     feature_acts = sae.encode(cache[sae.cfg.hook_name])\n",
    "\n",
    "#     # save some room\n",
    "#     del cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572cfd9e-c19a-4732-91fe-afded3193710",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d139ee-c2c0-4141-b1d3-51201532b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62183e3e-dc07-4553-8c20-29f77621360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60de6e3-14a7-4397-91e5-93806a51b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(torch.flatten(encoded_features[0]), k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62215d-c92b-462a-85e9-dfc0e9c797c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(torch.flatten(encoded_features[1]), k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c936f45c-b911-46c9-b001-4de483153bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(torch.flatten(encoded_features[2]), k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421c97d-4dc7-4f4d-9cbf-59fa19225ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify active neurons\n",
    "def get_active_neurons(encoded_tensor, threshold=0.1):\n",
    "    return (encoded_tensor > threshold).nonzero(as_tuple=True)[1].tolist()\n",
    "\n",
    "# Analyze activations for each text\n",
    "for i, text in enumerate(texts):\n",
    "    active_neurons = get_active_neurons(encoded_features[i])\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Active Neurons: {active_neurons}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479646dd-e769-407d-ac99-dbfefb90456c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
