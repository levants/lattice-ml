{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1df17-4dc9-4d72-9d4b-9582eb2e2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5867f5-3075-4cbe-b630-f4586f4ca151",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b7a2a-b1f5-4a4f-b9b8-ac7d34f3b76e",
   "metadata": {},
   "source": [
    "! pip install -U lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44042a-1211-4fa6-9a71-8ef4dfb417f9",
   "metadata": {},
   "source": [
    "# Organize Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4e81b-2cc6-4dc6-9a2f-03c1689747e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae67dc-5058-45d2-a7d9-e22524df0744",
   "metadata": {},
   "source": [
    "# Orginize Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93502da6-40e9-4b76-9dcf-5b3b09b2c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data')\n",
    "model_path = PATH / 'models' / '2_layer_fashion_mnist_classifier_positive'\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "MNIST_dir = PATH / 'fashion_mnist'\n",
    "MNIST_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e43d91-8859-44c4-a83d-e1ea66027c1f",
   "metadata": {},
   "source": [
    "# Initialize Device and Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6a4a4-bd17-490a-b57d-c54bebdf6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "workers = os.cpu_count()\n",
    "print(\"Number of CPUs in the system:\", workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5330aa4-0622-4277-b09e-809ec06f34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'gpu'  \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6b9f1-481b-4f36-a219-d02da60cb625",
   "metadata": {},
   "source": [
    "## Initialize Static Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752f0d3-edf0-4335-88fa-4d4ca2395fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 1e-4\n",
    "L1_LAMBDA = 1e-4\n",
    "EPOCHS = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ed557-3167-4dc4-851a-15b4e4229fa6",
   "metadata": {},
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c6afc-c40b-45cb-bdfb-493db6d85f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Weights Linear Layer\n",
    "class PositiveWeightLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(PositiveWeightLinear, self).__init__()\n",
    "        self.raw_weight = nn.Parameter(torch.randn(out_features, in_features) * 0.01)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        positive_weight = F.softplus(self.raw_weight)\n",
    "        return F.linear(x, positive_weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2ecf5-1732-49b3-9c88-d687cb0ebba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositiveWeightsNN(nn.Module):\n",
    "    \"\"\"MNIST classifier positive weights model\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc4 = PositiveWeightLinear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = self.fc1(x)\n",
    "        h = self.act1(h)\n",
    "        h = self.fc2(h)\n",
    "        h = self.act2(h)\n",
    "        h = self.fc3(h)\n",
    "        h = self.act3(h)\n",
    "        z = self.fc4(h)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6e67d-3314-4072-b193-6be2fcc48c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTClassifier(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY, l1_lambda=L1_LAMBDA):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.l1_lambda = l1_lambda\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def l1_regularization(self):\n",
    "        l1_norm = sum(p.abs().sum() for p in self.model.parameters() if p.requires_grad)\n",
    "        return self.l1_lambda * l1_norm\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        l1_loss = self.l1_regularization()\n",
    "        total_loss = loss + l1_loss\n",
    "\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('train_loss', total_loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return total_loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        epoch,\n",
    "        batch_idx,\n",
    "        optimizer,\n",
    "        optimizer_closure,\n",
    "    ):\n",
    "        # Execute the closure to run training_step, zero_grad, and backward.\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        \n",
    "        # (Optional) Custom logic: for example, enforcing positive weights:\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight\" in name and param.requires_grad:\n",
    "                param.data.clamp_(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d69186-11d9-483b-a523-c1105092b909",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402060d5-e4c4-43f1-8e32-5a39a36059e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "    ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0719297-21a8-453e-83fa-0f676e68383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "    train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, transform=train_transform, download=True)\n",
    "    test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, transform=val_transform, download=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e61dbc-3bc2-407b-88c2-a8c5a296ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaders\n",
    "train_loader, test_loader = get_data_loaders(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf18e38-70a4-45d8-9ee3-3983062ec47b",
   "metadata": {},
   "source": [
    "# Checkpointing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950bcc8f-3e3b-4bee-8c95-d645a853619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    "    filename=str(model_path / 'best-checkpoint'),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "last_checkpoint_callback = ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    filename=str(model_path / 'last-checkpoint'),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a7e94-d79d-4861-92fa-b13efa4ef8ff",
   "metadata": {},
   "source": [
    "# Initiate Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae9eb7-734e-47de-8be1-89e966e843ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = PositiveWeightsNN()\n",
    "\n",
    "# Model training\n",
    "model = FashionMNISTClassifier(net)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback, last_checkpoint_callback],\n",
    "    accelerator=device,\n",
    "    devices=1,\n",
    ")\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa129c-5e1f-41b3-9856-bf254770e3e4",
   "metadata": {},
   "source": [
    "# Visualize Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de5b22-1bda-4733-865d-6cc4cd47abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# Function to visualize learned features\n",
    "def visualize_weights(model, layer):\n",
    "    weights = model.state_dict()[layer].cpu().numpy()\n",
    "    fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < weights.shape[0]:\n",
    "            ax.imshow(weights[i].reshape(28, 28), cmap='gray')\n",
    "            ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb845d3-2348-4f39-9a26-7ebc47b7ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(model, 'model.fc1.weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66190cc-f0a6-4705-8564-748dcba02401",
   "metadata": {},
   "source": [
    "## Analysis of the Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbc8ca-589d-4ec0-9c10-bf8aaa942559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
