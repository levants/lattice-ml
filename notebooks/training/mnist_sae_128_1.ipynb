{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1df17-4dc9-4d72-9d4b-9582eb2e2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5867f5-3075-4cbe-b630-f4586f4ca151",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b7a2a-b1f5-4a4f-b9b8-ac7d34f3b76e",
   "metadata": {},
   "source": [
    "! pip install -U lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44042a-1211-4fa6-9a71-8ef4dfb417f9",
   "metadata": {},
   "source": [
    "# Organize Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4e81b-2cc6-4dc6-9a2f-03c1689747e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae67dc-5058-45d2-a7d9-e22524df0744",
   "metadata": {},
   "source": [
    "# Orginize Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93502da6-40e9-4b76-9dcf-5b3b09b2c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data')\n",
    "model_path = PATH / 'models' / '2_layer_128_64_sae_sigmoid'\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "MNIST_dir = PATH / 'mnist'\n",
    "MNIST_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e43d91-8859-44c4-a83d-e1ea66027c1f",
   "metadata": {},
   "source": [
    "# Initialize Device and Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6a4a4-bd17-490a-b57d-c54bebdf6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "workers = os.cpu_count()\n",
    "print(\"Number of CPUs in the system:\", workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5330aa4-0622-4277-b09e-809ec06f34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'gpu'  \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ed557-3167-4dc4-851a-15b4e4229fa6",
   "metadata": {},
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6e67d-3314-4072-b193-6be2fcc48c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "\n",
    "class SparseAutoencoder(L.LightningModule):\n",
    "    def __init__(self, input_dim=784, hidden_dim1=128, hidden_dim2=64, sparsity_target=0.05, sparsity_lambda=1e-3):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.sparsity_target = sparsity_target\n",
    "        self.sparsity_lambda = sparsity_lambda\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def compute_sparsity_penalty(self, hidden_representation):\n",
    "        p_hat = torch.mean(hidden_representation, dim=0)\n",
    "        kl_divergence = self.sparsity_target * torch.log(self.sparsity_target / p_hat) + \\\n",
    "                        (1 - self.sparsity_target) * torch.log((1 - self.sparsity_target) / (1 - p_hat))\n",
    "        sparsity_penalty = self.sparsity_lambda * torch.sum(kl_divergence)\n",
    "        return sparsity_penalty\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        reconstruction_loss = F.mse_loss(decoded, x)\n",
    "        sparsity_penalty = self.compute_sparsity_penalty(encoded)\n",
    "        loss = reconstruction_loss + sparsity_penalty\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        val_loss = F.mse_loss(decoded, x)\n",
    "        self.log('val_loss', val_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d69186-11d9-483b-a523-c1105092b909",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0719297-21a8-453e-83fa-0f676e68383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e61dbc-3bc2-407b-88c2-a8c5a296ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir='./data', batch_size=64, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf18e38-70a4-45d8-9ee3-3983062ec47b",
   "metadata": {},
   "source": [
    "# Checkpointing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798efc70-da6d-480e-94f5-f86c32367850",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_path = model_path / 'best-checkpoint'\n",
    "last_checkpoint_path = model_path / 'last-checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950bcc8f-3e3b-4bee-8c95-d645a853619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    "    filename=str(best_checkpoint_path),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "last_checkpoint_callback = ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    filename=str(last_checkpoint_path),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a7e94-d79d-4861-92fa-b13efa4ef8ff",
   "metadata": {},
   "source": [
    "# Initiate Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae9eb7-734e-47de-8be1-89e966e843ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "data_module = MNISTDataModule(\n",
    "    data_dir=MNIST_dir,\n",
    "    transform=transform,\n",
    ")\n",
    "model = SparseAutoencoder()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=64,\n",
    "    callbacks=[checkpoint_callback, last_checkpoint_callback],\n",
    "    accelerator=device,\n",
    "    devices=1  # Set to the number of GPUs available\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa129c-5e1f-41b3-9856-bf254770e3e4",
   "metadata": {},
   "source": [
    "# Visualize Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcf3de-a8e8-4d07-af28-c88ffe07b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {best_checkpoint_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f91a78-b67d-4457-abd4-ae86e296b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls lightning_logs/version_9/data/models/2_layer_128_64_sae_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f6c14-2d82-4da2-a0ba-af396c53c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_logs_path = Path('lightning_logs/version_9/data/models/2_layer_128_64_sae_sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636f4de-f7b1-44a1-9589-e75e4e1c79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_checkpoint_logs_path.exists():\n",
    "    model_pt = torch.load(best_checkpoint_logs_path / 'best-checkpoint.ckpt')\n",
    "else:\n",
    "    model_pt = None\n",
    "model_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de5b22-1bda-4733-865d-6cc4cd47abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "def visualize_layer_weights(model, layer_indices, num_features=16):\n",
    "    \"\"\"\n",
    "    Visualizes the weights of specified layers in the model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The neural network model containing the layers.\n",
    "    - layer_indices: List of indices of the layers to visualize.\n",
    "    - num_features: Number of features (neurons or filters) to visualize per layer.\n",
    "    \"\"\"\n",
    "    # Extract all layers from the model\n",
    "    layers = list(model.children())\n",
    "\n",
    "    for layer_index in layer_indices:\n",
    "        # Check if the specified layer index is within the valid range\n",
    "        if layer_index < 0 or layer_index >= len(layers):\n",
    "            raise IndexError(f\"Layer index {layer_index} is out of range. Model has {len(layers)} layers.\")\n",
    "\n",
    "        # Retrieve the specified layer\n",
    "        layer = layers[layer_index]\n",
    "\n",
    "        # Check if the layer has weights\n",
    "        if not hasattr(layer, 'weight'):\n",
    "            raise ValueError(f\"Layer at index {layer_index} does not have weights.\")\n",
    "\n",
    "        # Get the weights and move them to CPU\n",
    "        weights = layer.weight.data.cpu().numpy()\n",
    "\n",
    "        # Determine the type of layer and visualize accordingly\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            # For convolutional layers, visualize each filter\n",
    "            num_kernels = weights.shape[0]\n",
    "            num_cols = int(np.sqrt(num_features))\n",
    "            num_rows = int(np.ceil(num_features / num_cols))\n",
    "            fig = plt.figure(figsize=(num_cols * 2, num_rows * 2))\n",
    "            for i in range(min(num_features, num_kernels)):\n",
    "                ax = fig.add_subplot(num_rows, num_cols, i + 1)\n",
    "                kernel = weights[i]\n",
    "                # Normalize the kernel weights to [0, 1] for visualization\n",
    "                kernel = (kernel - kernel.min()) / (kernel.max() - kernel.min())\n",
    "                # For single-channel (grayscale) kernels\n",
    "                if kernel.shape[0] == 1:\n",
    "                    ax.imshow(kernel[0], cmap='gray')\n",
    "                else:\n",
    "                    # For multi-channel (e.g., RGB) kernels, transpose to (H, W, C)\n",
    "                    ax.imshow(np.transpose(kernel, (1, 2, 0)))\n",
    "                ax.axis('off')\n",
    "            plt.suptitle(f'Layer {layer_index} - Conv2d Weights')\n",
    "            plt.show()\n",
    "\n",
    "        elif isinstance(layer, nn.Linear):\n",
    "            # For fully connected layers, visualize each neuron's weights as heatmaps\n",
    "            plt.figure(figsize=(num_features, num_features))\n",
    "            for i in range(min(num_features, weights.shape[0])):\n",
    "                plt.subplot(int(np.sqrt(num_features)), int(np.sqrt(num_features)), i + 1)\n",
    "                # Reshape the weights to a 2D array for visualization\n",
    "                weight_matrix = weights[i].reshape(1, -1)  # Shape (1, input_dim)\n",
    "                plt.imshow(weight_matrix, cmap='viridis', aspect='auto')\n",
    "                plt.colorbar()\n",
    "                plt.axis('off')\n",
    "            plt.suptitle(f'Layer {layer_index} - Linear Weights')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Visualization for layer type {type(layer)} at index {layer_index} is not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb845d3-2348-4f39-9a26-7ebc47b7ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'encoder' is your encoder model instance\n",
    "visualize_layer_weights(model.encoder, layer_indices=[0, 2], num_features=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dda8cb-ad90-4fcf-a628-e4325319f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab7e41-8dab-4b9e-a10b-30ffe5566eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "def visualize_weights_as_heatmaps(model, layer_index, num_neurons=16):\n",
    "    \"\"\"\n",
    "    Visualizes the weights of a specified layer in the model as heatmaps.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The neural network model containing the layers.\n",
    "    - layer_index: Index of the layer to visualize.\n",
    "    - num_neurons: Number of neurons to visualize.\n",
    "    \"\"\"\n",
    "    # Extract the specified layer\n",
    "    layer = list(model.children())[layer_index]\n",
    "\n",
    "    # Check if the layer has weights\n",
    "    if not hasattr(layer, 'weight'):\n",
    "        raise ValueError(f\"Layer at index {layer_index} does not have weights.\")\n",
    "\n",
    "    # Get the weights and move them to CPU\n",
    "    weights = layer.weight.data.cpu().numpy()\n",
    "\n",
    "    # Plot heatmaps for the specified number of neurons\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i in range(min(num_neurons, weights.shape[0])):\n",
    "        plt.subplot(int(np.sqrt(num_neurons)), int(np.sqrt(num_neurons)), i + 1)\n",
    "        weight_matrix = weights[i].reshape(1, -1)  # Reshape to 2D for heatmap\n",
    "        plt.imshow(weight_matrix, cmap='viridis', aspect='auto')\n",
    "        plt.colorbar()\n",
    "        plt.title(f'Neuron {i}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f'Layer {layer_index} - Weights Heatmaps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a7568-28b9-43f2-bc48-a02cff3fe154",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights_as_heatmaps(model.encoder, layer_index=2, num_neurons=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a240650-c575-4043-84b2-636d029d3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_magnitudes(model, layer_index):\n",
    "    \"\"\"\n",
    "    Plots the magnitudes of weights for each neuron in the specified layer.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The neural network model containing the layers.\n",
    "    - layer_index: Index of the layer to visualize.\n",
    "    \"\"\"\n",
    "    # Extract the specified layer\n",
    "    layer = list(model.children())[layer_index]\n",
    "\n",
    "    # Check if the layer has weights\n",
    "    if not hasattr(layer, 'weight'):\n",
    "        raise ValueError(f\"Layer at index {layer_index} does not have weights.\")\n",
    "\n",
    "    # Get the weights and compute their magnitudes\n",
    "    weights = layer.weight.data.cpu().numpy()\n",
    "    magnitudes = np.linalg.norm(weights, axis=1)\n",
    "\n",
    "    # Plot the magnitudes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(magnitudes)), magnitudes)\n",
    "    plt.xlabel('Neuron Index')\n",
    "    plt.ylabel('Weight Magnitude')\n",
    "    plt.title(f'Layer {layer_index} - Weight Magnitudes')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e96f18-9196-49a5-bce3-0bf5c65e88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_magnitudes(model.encoder, layer_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97884fd9-621a-4624-8183-b0fea0bdfc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_distribution(model, layer_index):\n",
    "    \"\"\"\n",
    "    Plots the distribution of weights in the specified layer.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The neural network model containing the layers.\n",
    "    - layer_index: Index of the layer to visualize.\n",
    "    \"\"\"\n",
    "    # Extract the specified layer\n",
    "    layer = list(model.children())[layer_index]\n",
    "\n",
    "    # Check if the layer has weights\n",
    "    if not hasattr(layer, 'weight'):\n",
    "        raise ValueError(f\"Layer at index {layer_index} does not have weights.\")\n",
    "\n",
    "    # Get the weights\n",
    "    weights = layer.weight.data.cpu().numpy().flatten()\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(weights, bins=30, edgecolor='black')\n",
    "    plt.xlabel('Weight Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Layer {layer_index} - Weight Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683abd3c-4aaf-4996-a330-4f4584522346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_distribution(model.encoder, layer_index=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6f39b-1f34-4bb4-9bc4-fb6e99d5f5c6",
   "metadata": {},
   "source": [
    "# Activations by Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3543dc-d210-436a-8685-57cb81de2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf7a4f-15c5-4cba-995c-6478bdd364c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your encoder model\n",
    "class Encoder(object):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net= net.eval()\n",
    "        # Add more layers as needed\n",
    "\n",
    "    def eval(self):\n",
    "        self.net.eval()\n",
    "\n",
    "        return self\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, x):\n",
    "        activations = {}\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = self.net[0](x)\n",
    "        activations['layer0'] = x\n",
    "        x = self.net[1](x)\n",
    "        x = self.net[2](x)\n",
    "        activations['layer2'] = x\n",
    "        x = self.net[3](x)\n",
    "        # Continue forward pass\n",
    "        \n",
    "        return x, activations\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55132d-7009-49ec-9520-805a862339a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_dataset = datasets.MNIST(root=MNIST_dir, train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(mnist_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823051db-8b5e-4b49-b82c-7de0661190a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the encoder\n",
    "encoder = Encoder(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4123c1-6b50-4267-85c8-acb8b6e8cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e0932-0201-4ff4-955d-0d04d6ee081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c245ac-78df-4858-bf48-7e8b9b6133ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18486fda-8a2b-4a85-9edb-1a76a49683a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d326df-7716-4d19-bf74-833772ec0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9136fa3-6d45-4f11-ab71-7920ebd23946",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.net[0](x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edab0c-1fe2-4fd5-a585-cf40e6b23b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store activations by digit class\n",
    "activations_by_digit = {digit: {'layer0': [], 'layer2': []} for digit in range(10)}\n",
    "\n",
    "# Forward pass through the dataset\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        outputs, activations = encoder(images)\n",
    "        for i in range(images.size(0)):\n",
    "            digit = labels[i].item()\n",
    "            activations_by_digit[digit]['layer0'].append(activations['layer0'][i].numpy())\n",
    "            activations_by_digit[digit]['layer2'].append(activations['layer2'][i].numpy())\n",
    "\n",
    "# Compute average activations\n",
    "average_activations = {digit: {'layer0': None, 'layer2': None} for digit in range(10)}\n",
    "for digit in range(10):\n",
    "    average_activations[digit]['layer0'] = torch.tensor(activations_by_digit[digit]['layer0']).mean(dim=0)\n",
    "    average_activations[digit]['layer2'] = torch.tensor(activations_by_digit[digit]['layer2']).mean(dim=0)\n",
    "\n",
    "# Identify top 12 most and least active neurons\n",
    "top_neurons = {digit: {'layer0': {'most_active': None, 'least_active': None},\n",
    "                       'layer2': {'most_active': None, 'least_active': None}} for digit in range(10)}\n",
    "top_n = 24\n",
    "for digit in range(10):\n",
    "    for layer in ['layer0', 'layer2']:\n",
    "        avg_act = average_activations[digit][layer]\n",
    "        top_neurons[digit][layer]['most_active'] = sorted(torch.topk(avg_act, top_n).indices.tolist())\n",
    "        top_neurons[digit][layer]['least_active'] = sorted(torch.topk(-avg_act, top_n).indices.tolist())\n",
    "\n",
    "# Display results\n",
    "for digit in range(10):\n",
    "    print(f\"Digit {digit}:\")\n",
    "    for layer in ['layer0', 'layer2']:\n",
    "        print(f\"  Layer {layer}:\")\n",
    "        print(f\"    Most active neurons: {top_neurons[digit][layer]['most_active']}\")\n",
    "        print(f\"    Least active neurons: {top_neurons[digit][layer]['least_active']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c11b05-97c7-44ae-9f65-e39d822912b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
