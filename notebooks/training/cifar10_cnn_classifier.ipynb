{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1df17-4dc9-4d72-9d4b-9582eb2e2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5867f5-3075-4cbe-b630-f4586f4ca151",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b7a2a-b1f5-4a4f-b9b8-ac7d34f3b76e",
   "metadata": {},
   "source": [
    "! pip install -U lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44042a-1211-4fa6-9a71-8ef4dfb417f9",
   "metadata": {},
   "source": [
    "# Organize Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4e81b-2cc6-4dc6-9a2f-03c1689747e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae67dc-5058-45d2-a7d9-e22524df0744",
   "metadata": {},
   "source": [
    "# Orginize Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93502da6-40e9-4b76-9dcf-5b3b09b2c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data')\n",
    "model_path = PATH / 'models' / 'cifar10_cnn_classifier'\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "MNIST_dir = PATH / 'cifar'\n",
    "MNIST_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e43d91-8859-44c4-a83d-e1ea66027c1f",
   "metadata": {},
   "source": [
    "# Initialize Device and Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6a4a4-bd17-490a-b57d-c54bebdf6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "workers = os.cpu_count()\n",
    "print(\"Number of CPUs in the system:\", workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5330aa4-0622-4277-b09e-809ec06f34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'gpu'  \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6b9f1-481b-4f36-a219-d02da60cb625",
   "metadata": {},
   "source": [
    "## Initialize Static Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752f0d3-edf0-4335-88fa-4d4ca2395fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ed557-3167-4dc4-851a-15b4e4229fa6",
   "metadata": {},
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2ecf5-1732-49b3-9c88-d687cb0ebba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"CIFAR10 classifier model\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # Convolutional feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 3x32x32 -> 32x32x32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # 32x32x32 -> 32x16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 32x16x16 -> 64x16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # 64x16x16 -> 64x8x8\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 64x8x8 -> 128x8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)                              # 128x8x8 -> 128x4x4\n",
    "        )\n",
    "        # Global average pooling layer reduces each feature map to a single value.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # Classifier: dropout followed by a fully connected layer.\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # Global pooling: output shape becomes (batch_size, 128, 1, 1)\n",
    "        x = self.avgpool(x)\n",
    "        # Flatten the output: shape becomes (batch_size, 128)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6e67d-3314-4072-b193-6be2fcc48c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10LitModule(L.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3, weight_decay=1e-4, max_epochs=128):\n",
    "        super(CIFAR10LitModule, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs)\n",
    "        \n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d69186-11d9-483b-a523-c1105092b909",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402060d5-e4c4-43f1-8e32-5a39a36059e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "val_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2023, 0.1994, 0.2010))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0719297-21a8-453e-83fa-0f676e68383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "    train_dataset = datasets.CIFAR10(root='./data/cifar', train=True, transform=train_transform, download=True)\n",
    "    test_dataset = datasets.CIFAR10(root='./data/cifar', train=False, transform=val_transform, download=True)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=workers-1,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=workers-1,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e61dbc-3bc2-407b-88c2-a8c5a296ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaders\n",
    "train_loader, test_loader = get_data_loaders(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf18e38-70a4-45d8-9ee3-3983062ec47b",
   "metadata": {},
   "source": [
    "# Checkpointing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950bcc8f-3e3b-4bee-8c95-d645a853619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    "    filename=str(model_path / 'best-checkpoint'),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "last_checkpoint_callback = ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    filename=str(model_path / 'last-checkpoint'),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a7e94-d79d-4861-92fa-b13efa4ef8ff",
   "metadata": {},
   "source": [
    "# Initiate Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae9eb7-734e-47de-8be1-89e966e843ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(num_classes=10)\n",
    "\n",
    "# Model training\n",
    "model = CIFAR10LitModule(net, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, max_epochs=EPOCHS)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback, last_checkpoint_callback],\n",
    "    accelerator=device,\n",
    "    devices=1,\n",
    ")\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa129c-5e1f-41b3-9856-bf254770e3e4",
   "metadata": {},
   "source": [
    "# Visualize Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de5b22-1bda-4733-865d-6cc4cd47abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_convnet_weights(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Visualize the weight distributions of all trainable parameters in the model.\n",
    "    For each parameter (whose name includes \"weight\" and requires gradients), a histogram is displayed.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The convolutional network model whose weights will be visualized.\n",
    "    \"\"\"\n",
    "    # Iterate over all named parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name and param.requires_grad:\n",
    "            # Detach the parameter, move it to CPU, and flatten to a 1D array.\n",
    "            weights = param.detach().cpu().numpy().flatten()\n",
    "            \n",
    "            # Create a new figure for each parameter.\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(weights, bins=50, color='blue', alpha=0.7)\n",
    "            plt.title(f\"Weight Distribution for Layer: {name}\")\n",
    "            plt.xlabel(\"Weight Value\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb845d3-2348-4f39-9a26-7ebc47b7ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_convnet_weights(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac204c-de2e-4ab9-8128-c5b16cb652b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_convnet_kernels(model: nn.Module, conv_layer: nn.Module):\n",
    "    \"\"\"\n",
    "    Visualize the kernels (weights) of a convolutional layer in a ConvNet.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The convolutional network.\n",
    "        layer_name (str): The exact name of the convolution layer (as in model.named_modules())\n",
    "                          whose kernels you want to visualize.\n",
    "    \"\"\"\n",
    "    # Get the kernel weights: shape (out_channels, in_channels, kernel_h, kernel_w)\n",
    "    kernels = conv_layer.weight.data.clone().cpu()  # copy for visualization\n",
    "    num_kernels = kernels.shape[0]\n",
    "    \n",
    "    # Setup a grid for visualization.\n",
    "    grid_cols = int(np.ceil(np.sqrt(num_kernels)))\n",
    "    grid_rows = int(np.ceil(num_kernels / grid_cols))\n",
    "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols * 2, grid_rows * 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_kernels):\n",
    "        kernel = kernels[i]  # shape: (in_channels, kH, kW)\n",
    "        # If the kernel has 3 input channels, assume it's an RGB kernel.\n",
    "        if kernel.shape[0] == 3:\n",
    "            # Permute to (kH, kW, 3) for visualization.\n",
    "            kernel_img = kernel.permute(1, 2, 0)\n",
    "        else:\n",
    "            # Otherwise, average across channels to get a single-channel image.\n",
    "            kernel_img = kernel.mean(dim=0, keepdim=True).squeeze(0)\n",
    "        \n",
    "        # Normalize the kernel values to [0, 1] for better visualization.\n",
    "        kernel_img = kernel_img - kernel_img.min()\n",
    "        if kernel_img.max() != 0:\n",
    "            kernel_img = kernel_img / kernel_img.max()\n",
    "        else:\n",
    "            kernel_img = kernel_img\n",
    "\n",
    "        # Display the kernel.\n",
    "        if kernel_img.ndim == 3:\n",
    "            axes[i].imshow(kernel_img.numpy())\n",
    "        else:\n",
    "            axes[i].imshow(kernel_img.numpy(), cmap='gray')\n",
    "        axes[i].set_title(f\"Kernel {i}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Hide any extra subplots.\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de61703-8b80-4a22-945b-37bcc98de27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.model.features[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8acf8-41d3-43db-86d8-a55f9d0ce45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_convnet_kernels(model.model, model.model.features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a18c9c-77ad-4167-8391-4767016d39ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_convnet_kernels(model.model, model.model.features[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da67ce3-ec69-45c9-90b5-bd6d464eb405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4bdd6-178e-438b-a9ba-7a88b835f372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_convnet_kernels(model.model, model.model.features[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66190cc-f0a6-4705-8564-748dcba02401",
   "metadata": {},
   "source": [
    "## Analysis of the Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbc8ca-589d-4ec0-9c10-bf8aaa942559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
