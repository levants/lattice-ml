# lattice-ml

This repository implements a lattice‐theoretic formal concept framework for analyzing transcoder features in transformer‐based language models. Formal Concept Analysis (FCA) provides a mathematical basis—using complete lattices and Galois connections—for identifying and organizing interpretable “concepts” as extents (sets of objects) and intents (sets of attributes). Transcoders approximate densely activating MLP sublayers with sparsely activating ones, enabling fine‐grained circuit analysis of hidden features. Sparse autoencoders are used to learn efficient, sparse representations of neural activations, highlighting the most salient features for interpretability. Transcoders build on this by transforming dense activations into sparse feature patterns, a strategy that has been applied not only to LLMs but also to vision models: in language models, transcoders extract interpretable feature circuits from transformer layers, while in vision, sparse autoencoders and transcoders enable sparse circuit analysis of convolutional neural networks. By combining FCA with transcoder outputs, we derive formal contexts where objects correspond to model inputs or neuron activations and attributes correspond to transcoder features. This yields a concept lattice that reveals how features co‐occur and propagate across layers. The lattice facilitates operations such as join (least common superconcept) and meet (greatest common subconcept), uncovering hierarchies among feature sets and their neuron activations. Ultimately, this approach provides interpretable insights into which transcoder features drive specific behaviors or circuits inside GPT‐2‐style models.